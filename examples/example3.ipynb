{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "interpreted-overhead",
   "metadata": {},
   "source": [
    "# Example 3\n",
    "In the examples so far, we have shown how to compute the traction maps with images in the ideal format. In Example 3 we will demonstrate how you can process data with different input dimensions. We also make use of an experimental feature that predicts the ROI.\n",
    "\n",
    "\n",
    "Until the repo is made public you'll be required to enter a git token. This can be created by going to [GitHub](https://docs.github.com/en/github/authenticating-to-github/creating-a-personal-access-token) and only ticking the repo. Do not share this key. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-energy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "TOKEN = getpass('Enter the git token: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emerging-qualification",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://$TOKEN@github.com/rg314/pytraction.git\n",
    "!pip install pytraction/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endless-highway",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pytraction_get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-amount",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pytraction.core import TractionForce\n",
    "from pytraction.utils import plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simplified-canal",
   "metadata": {},
   "outputs": [],
   "source": [
    "pix_per_um = 1\n",
    "E = 3000 # Young's modulus in Pa\n",
    "\n",
    "img_path_bead = '../data/example3/Beads3.tif'\n",
    "img_path_cell = '../data/example3/Cell3.tif'\n",
    "ref_path = '../data/example3/BeadsStop.tif'\n",
    "\n",
    "traction_obj = TractionForce(pix_per_um, E=E, segment=True)\n",
    "img, ref, roi = traction_obj.load_data(img_path_bead, ref_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hawaiian-formula",
   "metadata": {},
   "source": [
    "Notice that when we try to load the data we get a RuntimeWarning because the input shape is not correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-douglas",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_bead = io.imread(img_path_bead)\n",
    "img_cell = io.imread(img_path_cell)\n",
    "ref = io.imread(ref_path)\n",
    "\n",
    "print(f'The shape of the bead image is {img_bead.shape}')\n",
    "print(f'The shape of the cell image is {img_cell.shape}')\n",
    "print(f'The shape of the reference image is {ref.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broke-ireland",
   "metadata": {},
   "source": [
    "All the images have 11 dimentions which could be a stack in space or time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extra-interstate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot every 2 bead slices\n",
    "fig, ax = plt.subplots(1,5, figsize=(16,16))\n",
    "for idx, axi in enumerate(ax.ravel()):\n",
    "    axi.set_title(f'beads slice {idx*2}')\n",
    "    axi.imshow(img_bead[idx*2,:,:], vmax=42168)\n",
    "    axi.set_axis_off()\n",
    "plt.tight_layout()\n",
    "\n",
    "# plot every 2 cell slices\n",
    "fig, ax = plt.subplots(1,5, figsize=(16,16))\n",
    "for idx, axi in enumerate(ax.ravel()):\n",
    "    axi.set_title(f'img slice {idx*2}')\n",
    "    axi.imshow(img_cell[idx*2,:,:], vmax=42168)\n",
    "    axi.set_axis_off()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apart-young",
   "metadata": {},
   "source": [
    "The intensity of both images decays as the number of slices increase and the beads become out of focus which suggests theses are z slices. Therefore, we should take the maximum Z projection of the stack in the 0th axis to get a (w,h) shaped image. We should then stack the bead and cell image together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-plane",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def z_project(img_path):\n",
    "    img = io.imread(img_path)\n",
    "    img_max= np.max(img, axis=0)\n",
    "    return img_max\n",
    "\n",
    "bead = z_project(img_path_bead)\n",
    "cell = z_project(img_path_cell)\n",
    "ref = z_project(ref_path)\n",
    "\n",
    "img = np.stack([[bead, cell]])\n",
    "ref = np.stack([ref, ref])\n",
    "\n",
    "print(f'The shape of the bead image is {img.shape}')\n",
    "print(f'The shape of the cell image is {ref.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suburban-dealing",
   "metadata": {},
   "source": [
    "The images now have the correct shapes. Notice that I used `np.stack([[bead, cell]])` for the `img` to ensure the shape is `(1, 2, 512, 512)`. Let's save the images to disk and reload them using `load_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaningful-internship",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save images to disk\n",
    "io.imsave('../data/example3/tfm.tif', img)\n",
    "io.imsave('../data/example3/tfm-ref.tif', ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-government",
   "metadata": {},
   "outputs": [],
   "source": [
    "pix_per_um = 1\n",
    "E = 3000 # Young's modulus in Pa\n",
    "\n",
    "img_path = '../data/example3/tfm.tif'\n",
    "ref_path = '../data/example3/tfm-ref.tif'\n",
    "\n",
    "traction_obj = TractionForce(pix_per_um, E=E, segment=True)\n",
    "img, ref, _ = traction_obj.load_data(img_path, ref_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serial-institution",
   "metadata": {},
   "source": [
    "This time no error message was returned. I also set `segment=True` which will have used an experimental feature to predict the ROI. Let's run the stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relative-jamaica",
   "metadata": {},
   "outputs": [],
   "source": [
    "log3 = traction_obj.process_stack(img, ref, verbose=0, crop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pharmaceutical-intelligence",
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame in range(len(log3)):\n",
    "    plot(log3, frame=frame, vmax=300, mask=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opening-greek",
   "metadata": {},
   "source": [
    "Note that no ROI was provided, and it was still possible to use the segment feature to locate the cell. If you are experiencing issues with this feature please raise an issue on the GitHub as this will allow us to update the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-techno",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(16,16))\n",
    "ax[0].imshow(img[0,1,:,:], cmap='gray')\n",
    "ax[0].set_axis_off()\n",
    "ax[0].set_title('Input image')\n",
    "\n",
    "ax[1].imshow(log3['cell_roi'][0], cmap='gray')\n",
    "ax[1].set_axis_off()\n",
    "ax[1].set_title('Auto-segment image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jewish-resort",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytraction",
   "language": "python",
   "name": "pytraction"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
